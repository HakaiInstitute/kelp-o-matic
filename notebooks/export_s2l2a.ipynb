{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "import torch\n",
    "\n",
    "EPS = 1e-10\n",
    "\n",
    "\n",
    "class SKeMaModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = smp.Unet(\n",
    "            encoder_name=\"tu-maxvit_tiny_tf_512\",\n",
    "            in_channels=10,\n",
    "            encoder_weights=None,\n",
    "        )\n",
    "\n",
    "        self.register_buffer(\n",
    "            \"per_channel_mean\",\n",
    "            torch.tensor([\n",
    "                1.93357159e02,\n",
    "                2.53693333e02,\n",
    "                1.41648022e02,\n",
    "                9.99292362e02,\n",
    "                3.21693919e02,\n",
    "                6.49704998e-02,\n",
    "                1.57273007e-01,\n",
    "                -1.57273007e-01,\n",
    "                1.82229161e07,\n",
    "                1.09806622e-01,\n",
    "            ]).view(1, -1, 1, 1),\n",
    "        )\n",
    "\n",
    "        self.register_buffer(\n",
    "            \"per_channel_std\",\n",
    "            torch.tensor([\n",
    "                1.55697494e02,\n",
    "                2.12700364e02,\n",
    "                2.04018106e02,\n",
    "                1.27588129e03,\n",
    "                3.77324432e02,\n",
    "                6.75251176e-01,\n",
    "                7.32966188e-01,\n",
    "                7.32966188e-01,\n",
    "                2.16768826e10,\n",
    "                4.11232123e-01,\n",
    "            ]).view(1, -1, 1, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Unpack spectral bands\n",
    "        blue = x.select(1, 0).unsqueeze(1)\n",
    "        green = x.select(1, 1).unsqueeze(1)\n",
    "        red = x.select(1, 2).unsqueeze(1)\n",
    "        nir = x.select(1, 3).unsqueeze(1)\n",
    "        re = x.select(1, 4).unsqueeze(1)\n",
    "\n",
    "        # Compute vegetation indices\n",
    "        ndvi = self.normalized_index(nir, red)\n",
    "        gndvi = self.normalized_index(nir, green)\n",
    "        ndvi_re = self.normalized_index(re, red)\n",
    "\n",
    "        # Compute other indices\n",
    "        ndwi = self.normalized_index(green, nir)\n",
    "        chl_green = (nir / (green + EPS)) - 1  # Chlorophyll Index Green\n",
    "\n",
    "        # Stack all bands and indices\n",
    "        x_aug = torch.cat([blue, green, red, nir, re, ndvi, ndwi, gndvi, chl_green, ndvi_re], dim=1)\n",
    "\n",
    "        x_aug_normalized = (x_aug - self.per_channel_mean) / self.per_channel_std\n",
    "\n",
    "        return self.model(x_aug_normalized)\n",
    "\n",
    "    @staticmethod\n",
    "    def normalized_index(a, b):\n",
    "        return (a - b) / (a + b + EPS)\n",
    "\n",
    "\n",
    "model = SKeMaModel()\n",
    "\n",
    "sample_input = torch.rand((2, 5, 512, 512), device=torch.device(\"cpu\"), requires_grad=False)\n",
    "model(sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4f4a75e714ffad",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = torch.load(\"./Unet_tu-maxvit_tiny_tf_512_20250818_164043.ckpt\")\n",
    "state_dict = ckpt[\"state_dict\"]\n",
    "\n",
    "# Update keys\n",
    "del state_dict[\"mean\"]\n",
    "del state_dict[\"std\"]\n",
    "model.load_state_dict(state_dict, strict=False)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad1d1c326a10b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(\n",
    "    model,\n",
    "    sample_input,\n",
    "    \"./Unet_tu-maxvit_tiny_tf_512_20250818_164043.onnx\",\n",
    "    input_names=[\"input\"],\n",
    "    output_names=[\"output\"],\n",
    "    export_params=True,  # Store model weights in the model file\n",
    "    opset_version=15,  # ONNX opset version\n",
    "    do_constant_folding=True,  # Optimize constants\n",
    "    verbose=False,\n",
    "    dynamic_axes={\"input\": {0: \"batch_size\"}, \"output\": {0: \"batch_size\"}},\n",
    "    # dynamic_shapes={\"x\": (torch.export.Dim(\"batch\"), 5, 512, 512)},\n",
    "    # dynamo=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
